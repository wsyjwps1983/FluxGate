"""
ä¸»ç¨‹åº
æ•´åˆè®­ç»ƒã€é¢„æµ‹å’Œæ¨¡å‹ç®¡ç†åŠŸèƒ½
"""

import os
import sys
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from app.model_trainer import IntentRouterTrainer
from app.model_predictor import IntentRouterPredictor

def setup_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„"""
    # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
    models_dir = os.path.join(project_root, "app", "models")
    os.makedirs(models_dir, exist_ok=True)
    
    # åˆ›å»ºç»“æœè¾“å‡ºç›®å½•
    results_dir = os.path.join(project_root, "app", "results")
    os.makedirs(results_dir, exist_ok=True)
    
    return models_dir, results_dir

def train_model(args):
    """è®­ç»ƒæ¨¡å‹å‘½ä»¤"""
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ„å›¾è¯†åˆ«æ¨¡å‹")
    print("=" * 50)
    
    # è®¾ç½®ç›®å½•
    models_dir, _ = setup_directories()
    
    # å‚æ•°æ£€æŸ¥
    if not os.path.exists(args.data_path):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data_path}")
        return False
    
    # ç”Ÿæˆæ¨¡å‹æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_filename = f"intent_router_{timestamp}.json"
    model_path = os.path.join(models_dir, model_filename)
    
    print(f"ğŸ“‚ è®­ç»ƒæ•°æ®: {args.data_path}")
    print(f"ğŸ’¾ æ¨¡å‹å°†ä¿å­˜åˆ°: {model_path}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = IntentRouterTrainer(
        encoder_name=args.encoder_name,
        score_threshold=args.threshold,
        api_key=args.api_key
    )
    
    # æ ¹æ®å‚æ•°é€‰æ‹©æ˜¯å¦è¿›è¡Œé˜ˆå€¼ä¼˜åŒ–
    if args.optimize_thresholds:
        # å¸¦é˜ˆå€¼ä¼˜åŒ–çš„è®­ç»ƒ
        results = trainer.train_with_threshold_optimization(
            data_path=args.data_path,
            save_path=model_path,
            optimization_method=args.optimization_method
        )
        success = results['success']
        if success:
            print("\nğŸ‰ é˜ˆå€¼ä¼˜åŒ–è®­ç»ƒå®Œæˆï¼")
            opt_results = results.get('optimization_results', {})
            print(f"ğŸ“Š ä¼˜åŒ–å‰å‡†ç¡®ç‡: {opt_results.get('initial_accuracy', 0):.1f}%")
            print(f"ğŸ“Š ä¼˜åŒ–åå‡†ç¡®ç‡: {opt_results.get('optimized_accuracy', 0):.1f}%")
            print(f"ğŸ“ˆ å‡†ç¡®ç‡æå‡: {opt_results.get('improvement', 0):+.1f}%")
            
            # æ‰“å°ä¼˜åŒ–åçš„é˜ˆå€¼
            optimized_thresholds = opt_results.get('optimized_thresholds')
            if optimized_thresholds:
                print("\nğŸ“‹ ä¼˜åŒ–åçš„è·¯ç”±é˜ˆå€¼:")
                for route_name, threshold in optimized_thresholds.items():
                    print(f"    - {route_name}: {threshold:.3f}")
    else:
        # æ™®é€šè®­ç»ƒ
        success = trainer.train_and_save(
            data_path=args.data_path,
            save_path=model_path
        )
    
    if success:
        print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ’¾ æ¨¡å‹æ–‡ä»¶: {model_path}")
        print(f"ğŸ’¡ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œé¢„æµ‹:")
        print(f"   python -m app.main predict --model {model_path}")
    
    return success

def predict_model(args):
    """é¢„æµ‹å‘½ä»¤"""
    print("ğŸ¤– æ„å›¾è¯†åˆ«é¢„æµ‹")
    print("=" * 50)
    
    # å‚æ•°æ£€æŸ¥
    if not os.path.exists(args.model):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        return False
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = IntentRouterPredictor(
        model_path=args.model,
        api_key=args.api_key
    )
    
    # åŠ è½½æ¨¡å‹
    if not predictor.load_model():
        return False
    
    # æ ¹æ®ä¸åŒæ¨¡å¼æ‰§è¡Œé¢„æµ‹
    if args.interactive:
        # äº¤äº’å¼æ¨¡å¼
        predictor.interactive_mode()
    
    elif args.query:
        # å•ä¸ªæŸ¥è¯¢
        result = predictor.predict(args.query, return_details=True)
        intent = result['intent']
        score = result.get('score', None)
        
        if intent:
            print(f"ğŸ¯ è¯†åˆ«æ„å›¾: {intent}")
            if score:
                print(f"ğŸ“Š åŒ¹é…åˆ†æ•°: {score:.4f}")
        else:
            print("â“ æœªè¯†åˆ«åˆ°æ„å›¾")
    
    elif args.batch_file:
        # æ‰¹é‡é¢„æµ‹
        if not os.path.exists(args.batch_file):
            print(f"âŒ æ‰¹é‡æŸ¥è¯¢æ–‡ä»¶ä¸å­˜åœ¨: {args.batch_file}")
            return False
        
        # è¯»å–æŸ¥è¯¢
        with open(args.batch_file, 'r', encoding='utf-8') as f:
            queries = [line.strip() for line in f if line.strip()]
        
        print(f"ğŸ“Š æ­£åœ¨å¤„ç† {len(queries)} æ¡æŸ¥è¯¢...")
        
        # æ‰¹é‡é¢„æµ‹
        results = predictor.predict_batch(queries, return_details=True)
        
        # è®¾ç½®ç»“æœç›®å½•
        _, results_dir = setup_directories()
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"predictions_{timestamp}.csv"
        output_path = os.path.join(results_dir, output_filename)
        
        # å¯¼å‡ºç»“æœ
        predictor.export_predictions(queries, output_path)
        
        # æ‰“å°éƒ¨åˆ†ç»“æœ
        print("\né¢„æµ‹ç»“æœé¢„è§ˆ:")
        for i, (query, result) in enumerate(zip(queries[:10], results[:10])):
            intent = result['intent']
            print(f"  {i+1}. {query[:50]}{'...' if len(query) > 50 else ''} -> {intent or 'None'}")
        
        if len(queries) > 10:
            print(f"  ... è¿˜æœ‰ {len(queries) - 10} æ¡ç»“æœ")
        
        print(f"\nğŸ“Š å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    else:
        print("âŒ è¯·æä¾›æŸ¥è¯¢å‚æ•°: --query, --batch-file æˆ– --interactive")
        return False
    
    return True

def evaluate_model(args):
    """è¯„ä¼°æ¨¡å‹å‘½ä»¤"""
    print("ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½")
    print("=" * 50)
    
    # å‚æ•°æ£€æŸ¥
    if not os.path.exists(args.model):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        return False
    
    if not os.path.exists(args.test_data):
        print(f"âŒ æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.test_data}")
        return False
    
    # åˆ›å»ºé¢„æµ‹å™¨å¹¶åŠ è½½æ¨¡å‹
    predictor = IntentRouterPredictor(
        model_path=args.model,
        api_key=args.api_key
    )
    
    if not predictor.load_model():
        return False
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    from app.data_loader import load_intent_data
    test_data_dict = load_intent_data(args.test_data)
    
    # è½¬æ¢ä¸ºæµ‹è¯•æ ¼å¼
    test_queries = []
    for intent, utterances in test_data_dict.items():
        for utterance in utterances[:3]:  # æ¯ä¸ªæ„å›¾å–3æ¡ä½œä¸ºæµ‹è¯•
            test_queries.append((utterance, intent))
    
    print(f"ğŸ“Š ä½¿ç”¨ {len(test_queries)} æ¡æµ‹è¯•æ•°æ®è¿›è¡Œè¯„ä¼°")
    
    # è¯„ä¼°
    evaluation = predictor.evaluate_with_test_data(test_queries)
    
    # è®¾ç½®ç»“æœç›®å½•
    _, results_dir = setup_directories()
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    eval_filename = f"evaluation_{timestamp}.json"
    eval_path = os.path.join(results_dir, eval_filename)
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    import json
    with open(eval_path, 'w', encoding='utf-8') as f:
        # åºåˆ—åŒ–è¯„ä¼°ç»“æœï¼Œç§»é™¤ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        serializable_eval = {
            'total_samples': evaluation['total_samples'],
            'correct_predictions': evaluation['correct_predictions'],
            'accuracy': evaluation['accuracy'],
            'intent_stats': evaluation['intent_stats'],
            'model_info': predictor.model_info,
            'timestamp': timestamp
        }
        json.dump(serializable_eval, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {eval_path}")
    
    return True

def list_models(args):
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    print("ğŸ“‚ å¯ç”¨æ¨¡å‹åˆ—è¡¨")
    print("=" * 50)
    
    models_dir, _ = setup_directories()
    
    if not os.path.exists(models_dir):
        print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
        return False
    
    model_files = [f for f in os.listdir(models_dir) if f.endswith(('.pkl', '.json'))]
    
    if not model_files:
        print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
        return False
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹:")
    for i, model_file in enumerate(sorted(model_files), 1):
        model_path = os.path.join(models_dir, model_file)
        
        # è·å–æ¨¡å‹åŸºæœ¬ä¿¡æ¯
        try:
            if model_file.endswith('.json'):
                # è¯»å–JSONæ ¼å¼æ¨¡å‹
                import json
                with open(model_path, 'r', encoding='utf-8') as f:
                    save_data = json.load(f)
                file_type = "JSON"
            else:
                # è¯»å–Pickleæ ¼å¼æ¨¡å‹
                import pickle
                with open(model_path, 'rb') as f:
                    save_data = pickle.load(f)
                file_type = "Pickle"
            
            metadata = save_data.get('metadata', {})
            timestamp = save_data.get('timestamp', 'Unknown')
            version = save_data.get('version', 'Unknown')
            
            print(f"  {i}. {model_file} ({file_type})")
            print(f"     è·¯ç”±æ•°: {metadata.get('num_routes', 'Unknown')}")
            print(f"     è¯­å¥æ•°: {metadata.get('total_utterances', 'Unknown')}")
            print(f"     ç‰ˆæœ¬: {version}")
            print(f"     è®­ç»ƒæ—¶é—´: {timestamp}")
            print()
            
        except Exception as e:
            print(f"  {i}. {model_file} (è¯»å–ä¿¡æ¯å¤±è´¥: {e})")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ„å›¾è¯†åˆ«ç³»ç»Ÿ - SiliconFlowé›†æˆ")
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # è®­ç»ƒå‘½ä»¤
    train_parser = subparsers.add_parser('train', help='è®­ç»ƒæ¨¡å‹')
    train_parser.add_argument('--data-path', required=True, help='è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„ (Excel)')
    train_parser.add_argument('--api-key', help='SiliconFlow APIå¯†é’¥ (æˆ–è®¾ç½®SILICONFLOW_API_KEYç¯å¢ƒå˜é‡)')
    train_parser.add_argument('--encoder-name', default='BAAI/bge-large-zh-v1.5', help='ç¼–ç å™¨æ¨¡å‹åç§°')
    train_parser.add_argument('--threshold', type=float, default=0.3, help='åŒ¹é…é˜ˆå€¼')
    train_parser.add_argument('--optimize-thresholds', action='store_true', help='å¯ç”¨é˜ˆå€¼ä¼˜åŒ–')
    train_parser.add_argument('--optimization-method', choices=['automatic', 'manual'], default='automatic', help='é˜ˆå€¼ä¼˜åŒ–æ–¹æ³•')
    
    # é¢„æµ‹å‘½ä»¤
    predict_parser = subparsers.add_parser('predict', help='ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹')
    predict_parser.add_argument('--model', required=True, help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    predict_parser.add_argument('--api-key', help='SiliconFlow APIå¯†é’¥')
    predict_parser.add_argument('--query', help='å•ä¸ªæŸ¥è¯¢')
    predict_parser.add_argument('--batch-file', help='æ‰¹é‡æŸ¥è¯¢æ–‡ä»¶è·¯å¾„ (æ¯è¡Œä¸€ä¸ªæŸ¥è¯¢)')
    predict_parser.add_argument('--interactive', action='store_true', help='äº¤äº’å¼é¢„æµ‹æ¨¡å¼')
    
    # è¯„ä¼°å‘½ä»¤
    eval_parser = subparsers.add_parser('evaluate', help='è¯„ä¼°æ¨¡å‹æ€§èƒ½')
    eval_parser.add_argument('--model', required=True, help='æ¨¡å‹æ–‡ä»¶è·¯å¾„')
    eval_parser.add_argument('--test-data', required=True, help='æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„ (Excel)')
    eval_parser.add_argument('--api-key', help='SiliconFlow APIå¯†é’¥')
    
    # åˆ—å‡ºæ¨¡å‹å‘½ä»¤
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºå¯ç”¨æ¨¡å‹')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # è®¾ç½®APIå¯†é’¥ç¯å¢ƒå˜é‡
    if hasattr(args, 'api_key') and args.api_key:
        os.environ["SILICONFLOW_API_KEY"] = args.api_key
    
    # æ‰§è¡Œå‘½ä»¤
    try:
        if args.command == 'train':
            success = train_model(args)
        elif args.command == 'predict':
            success = predict_model(args)
        elif args.command == 'evaluate':
            success = evaluate_model(args)
        elif args.command == 'list':
            success = list_models(args)
        else:
            print(f"âŒ æœªçŸ¥å‘½ä»¤: {args.command}")
            success = False
        
        if not success:
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ“ä½œå·²å–æ¶ˆ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()